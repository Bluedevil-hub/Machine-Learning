{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Performance_metrics_Instructions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV"
      },
      "source": [
        "# Compute performance metrics for the given Y and Y_score without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHb6NE7Qvnc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "# other than these two you should not import any other packages"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ref\n",
        "#https://www.nbshare.io/notebook/626706996/Learn-And-Code-Confusion-Matrix-With-Python/\n",
        "#https://www.askpython.com/python-modules/pandas/update-the-value-of-a-row-dataframe\n",
        "#https://www.youtube.com/watch?v=HJkInJV29t8&t=12s\n",
        "#https://datagy.io/mean-squared-error-python/\n",
        "\n",
        "\n",
        "\n",
        "def confusion_mat(df):\n",
        "  #df['predicted'] = df['predicted'].apply(lambda x:1 if x >= 0.5 else 0 )\n",
        "  #df should have 2 cols name actual and predicted\n",
        "\n",
        "  TN = ((df['actual'] == 0) & (df['predicted'] == 0)).sum()\n",
        "  TP = ((df['actual'] == 1) & (df['predicted'] == 1)).sum()\n",
        "  FN = ((df['actual'] == 1) & (df['predicted'] == 0)).sum()\n",
        "  FP = ((df['actual'] == 0) & (df['predicted'] == 1)).sum()\n",
        "  return TN,TP,FN,FP\n",
        "\n",
        "\n",
        "def f1_score(df):\n",
        "  TN,TP,FN,FP = confusion_mat(df)\n",
        "  precision = TP/(TP + FP)\n",
        "  recall = TP/(FN + TP)\n",
        "  f1 = 2*((precision*recall)/(precision + recall))\n",
        "  return f1\n",
        "\n",
        "\n",
        "def accuracy_mat(df):\n",
        "  TN = ((df['actual'] == 0) & (df['predicted'] == 0)).sum()\n",
        "  TP = ((df['actual'] == 1) & (df['predicted'] == 1)).sum()\n",
        "  return (TN+TP)/len(df)\n",
        "\n",
        "\n",
        "def auc(df):\n",
        "  tpr = []\n",
        "  fpr = []\n",
        "  df = df.sort_values(by = ['predicted'], ascending = False)\n",
        "  #print(df,' This is df')\n",
        "  \n",
        "  \n",
        "  for i in tqdm(range(0,len(df))):\n",
        "    df_c = df.copy()\n",
        "    df_c['predicted'] = np.where(df_c['predicted'] >= df_c.iloc[i]['predicted'],1,0)\n",
        "    #print(df_c)\n",
        "\n",
        "    TN,TP,FN,FP = confusion_mat(df_c)\n",
        "    \n",
        "    fpr.append(FP/(TN + FP))\n",
        "    tpr.append(TP/(TP + FN))\n",
        "    #print(tpr)\n",
        "    #print(fpr,'Fpr')\n",
        "  \n",
        "  auc = np.trapz(tpr,fpr)\n",
        "  return auc\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sGXi4odT-4T0"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sir I tried diffearent way to update thresholds\n",
        "# df_copy['predicted'] = df_copy['predicted'].apply(lambda x:1 if x >= i else 0 )\n",
        "#df_copy.loc[df_copy['predicted'] < i] = 0 \n",
        "#df_copy.loc[df_copy['predicted'] >= i] = 1\n"
      ],
      "metadata": {
        "id": "xi2SpMhYD5U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbsWXuDaQvnq"
      },
      "source": [
        "\n",
        "## A. Compute performance metrics for the given data '5_a.csv'\n",
        " <pre>  <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
        "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFLW7oBQvnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882310ad-2191-47ff-f050-90d250a9ddb6"
      },
      "source": [
        "df_a=pd.read_csv('5_a.csv')\n",
        "\n",
        "df_a.columns = ['actual','predicted']\n",
        "print(df_a.head())\n",
        "df_a['predicted'] = df_a['predicted'].apply((lambda x : 1 if x > 0.5 else 1))\n",
        "print(df_a.head())\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actual  predicted\n",
            "0     1.0   0.637387\n",
            "1     1.0   0.635165\n",
            "2     1.0   0.766586\n",
            "3     1.0   0.724564\n",
            "4     1.0   0.889199\n",
            "   actual  predicted\n",
            "0     1.0          1\n",
            "1     1.0          1\n",
            "2     1.0          1\n",
            "3     1.0          1\n",
            "4     1.0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TN,TP,FN,FP = confusion_mat(df_a)\n",
        "print('True Negative' ,TN)\n",
        "print('True Positive', TP)\n",
        "print('False Positive', FP)\n",
        "print('False Negative',FN)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "accuracy = accuracy_mat(df_a)\n",
        "print('Accuracy:',accuracy)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "f1_score = f1_score(df_a)\n",
        "print('F1 score ',f1_score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTP3VqLQB5Ho",
        "outputId": "ac721c43-d421-4c4d-ffcd-226f4d54aa1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Negative 0\n",
            "True Positive 10000\n",
            "False Positive 100\n",
            "False Negative 0\n",
            "\n",
            "\n",
            "Accuracy: 0.9900990099009901\n",
            "\n",
            "\n",
            "F1 score  0.9950248756218906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_a=pd.read_csv('5_a.csv')\n",
        "\n",
        "df_a.columns = ['actual','predicted']\n",
        "\n",
        "auc_val = auc(df_a)\n",
        "print(auc_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-hc2EGgBynA",
        "outputId": "cbfc82f0-206e-4f87-e5ab-a5590c0fb80e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10100/10100 [00:31<00:00, 315.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.48829900000000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg8uUJvGAfCM"
      },
      "source": [
        "# write your code here for task A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KZem1BQvn2"
      },
      "source": [
        "\n",
        "\n",
        "## B. Compute performance metrics for the given data '5_b.csv'\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a>\n",
        "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sKlq0YQvn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256c21c1-0fdc-4ad4-ad2f-c3aa713613ee"
      },
      "source": [
        "df_b=pd.read_csv('5_b.csv')\n",
        "df_b.head()\n",
        "\n",
        "df_b.columns = ['actual','predicted']\n",
        "print(df_b.head())\n",
        "df_b['predicted'] = df_b['predicted'].apply((lambda x : 0 if x < 0.5 else 1))\n",
        "print(df_b.head())"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actual  predicted\n",
            "0     0.0   0.281035\n",
            "1     0.0   0.465152\n",
            "2     0.0   0.352793\n",
            "3     0.0   0.157818\n",
            "4     0.0   0.276648\n",
            "   actual  predicted\n",
            "0     0.0          0\n",
            "1     0.0          0\n",
            "2     0.0          0\n",
            "3     0.0          0\n",
            "4     0.0          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_b['predicted'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QupGT0KTSHt4",
        "outputId": "7d9de2d5-8417-44c6-d642-f1fc45a0e27e"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9806\n",
              "1     294\n",
              "Name: predicted, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlLVa-cVAfCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843a8af4-ea0e-4f09-8ca7-6eb6f35b711f"
      },
      "source": [
        "# write your code here for task B\n",
        "\n",
        "TN,TP,FN,FP = confusion_mat(df_b)\n",
        "print('True Negative' ,TN)\n",
        "print('True Positive', TP)\n",
        "print('False Positive', FP)\n",
        "print('False Negative',FN)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "accuracy = accuracy_mat(df_b)\n",
        "print('Accuracy:',accuracy)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "f1_score = f1_score(df_b)\n",
        "print('F1 score ',f1_score)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Negative 9761\n",
            "True Positive 55\n",
            "False Positive 239\n",
            "False Negative 45\n",
            "\n",
            "\n",
            "Accuracy: 0.9718811881188119\n",
            "\n",
            "\n",
            "F1 score  0.2791878172588833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_b=pd.read_csv('5_b.csv')\n",
        "\n",
        "df_b.columns = ['actual','predicted']\n",
        "\n",
        "auc_val = auc(df_b)\n",
        "print(auc_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnn84nVtErjd",
        "outputId": "8a06a64e-02a6-4070-ae16-358a72f85d7f"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10100/10100 [00:26<00:00, 385.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9377570000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiPGonTzQvoB"
      },
      "source": [
        "### C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data \n",
        "<br>\n",
        "\n",
        "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
        "\n",
        "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
        "\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HIJzq1QvoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2cbca2f-6e54-4a97-e19d-916628e07541"
      },
      "source": [
        "df_c=pd.read_csv('5_c.csv')\n",
        "\n",
        "df_c.columns = ['actual','predicted']\n",
        "print(df_c.head())\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actual  predicted\n",
            "0       0   0.458521\n",
            "1       0   0.505037\n",
            "2       0   0.418652\n",
            "3       0   0.412057\n",
            "4       0   0.375579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAPjewjzAfCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fe4e45-f585-4cf7-d709-9377d7644384"
      },
      "source": [
        " # write your code for task C\n",
        "\n",
        "def best_threshold(df):\n",
        "\n",
        "  threshold = []\n",
        "  A_val = []\n",
        "  df = df.sort_values(by = ['predicted'], ascending = False)\n",
        "  #print(df,' This is df')\n",
        "  \n",
        "  \n",
        "  for i in tqdm(range(0,len(df))):\n",
        "    df_c = df.copy()\n",
        "    threshold.append(df_c.iloc[i]['predicted'])\n",
        "    #print(df_c.iloc[i]['predicted'], ' I am thres')\n",
        "    df_c['predicted'] = np.where(df_c['predicted'] >= df_c.iloc[i]['predicted'],1,0)\n",
        "    #print(df_c)\n",
        "\n",
        "\n",
        "    TN,TP,FN,FP = confusion_mat(df_c)\n",
        "    A_val.append(500*FN + 100* FP)\n",
        "    \n",
        "\n",
        "  return threshold[np.argmin(A_val)]\n",
        "\n",
        "A_min = best_threshold(df_c)\n",
        "print(A_min)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2852/2852 [00:08<00:00, 354.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2300390278970873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD4CcgjXQvoL"
      },
      "source": [
        "\n",
        "## D.</b></font> Compute performance metrics(for regression) for the given data 5_d.csv\n",
        "<pre>    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
        "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
        "<ol>\n",
        "<li> Compute Mean Square Error </li>\n",
        "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
        "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVOj-bF9AfCd"
      },
      "source": [
        "df_d=pd.read_csv('5_d.csv')\n",
        "df_d.head()\n",
        "df_d.columns = ['actual', 'predicted']\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRhL1pheAfCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64952b0d-238b-4667-d6ce-8a74949996db"
      },
      "source": [
        " # write your code for task 5d\n",
        "\n",
        "def metrics(df):\n",
        "  y = np.array(df['actual'])\n",
        "  y_hat = np.array(df['predicted'])\n",
        "\n",
        "  mse = np.sum(np.power(y - y_hat, 2))/len(y)\n",
        "\n",
        "  mpe = np.sum(np.abs(y - y_hat)) / np.sum(y)\n",
        "\n",
        "  y_mean = np.mean(np.abs(y))\n",
        "  residual_square = np.sum(np.power(y-y_hat, 2))\n",
        "  total_sum = np.sum(np.power(y- y_mean,2))\n",
        "  r2 = 1 - (residual_square/total_sum)\n",
        "  \n",
        "  return mse,mpe,r2\n",
        "\n",
        "  \n",
        "\n",
        "mse, mpe,r2 = metrics(df_d)\n",
        "\n",
        "print('MSE', mse)\n",
        "print('MPE', mpe)\n",
        "print('r_square', r2)\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE 177.16569974554707\n",
            "MPE 0.1291202994009687\n",
            "r_square 0.9563582786990937\n"
          ]
        }
      ]
    }
  ]
}